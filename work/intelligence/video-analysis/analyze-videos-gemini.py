#!/usr/bin/env python3
"""
Gemini 2.5 Flash Video Analysis
Direct video analysis for Luoxi incident footage
Generated by CEO Agent - Phase 1.5 (FINAL)
"""

import google.generativeai as genai
import os
import json
import glob
import time
from pathlib import Path
from datetime import datetime

# Configuration
VIDEO_DIR = Path("../../../media")
OUTPUT_DIR = Path(".")
REPORTS_DIR = OUTPUT_DIR / "reports"

class GeminiVideoAnalyzer:
    def __init__(self):
        # Configure Gemini
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            raise ValueError("GOOGLE_API_KEY environment variable not set")

        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel("gemini-2.5-flash")
        self.results = []

    def analyze_video(self, video_path):
        """Analyze single video with Gemini 2.5 Flash"""
        video_name = Path(video_path).stem
        print(f"\nAnalyzing: {video_name}")
        print(f"  File: {Path(video_path).name}")

        # Upload video file
        print(f"  → Uploading video to Gemini...")
        try:
            video_file = genai.upload_file(path=str(video_path))
            print(f"  ✓ Uploaded: {video_file.name}")
        except Exception as e:
            print(f"  ✗ Upload failed: {e}")
            return None

        # Wait for processing
        print(f"  → Processing video...")
        max_wait = 60  # 60 seconds max wait
        waited = 0
        while video_file.state.name == "PROCESSING" and waited < max_wait:
            time.sleep(2)
            waited += 2
            video_file = genai.get_file(video_file.name)
            if waited % 10 == 0:
                print(f"    Still processing... ({waited}s)")

        if video_file.state.name == "FAILED":
            print(f"  ✗ Video processing failed")
            return None

        if video_file.state.name != "ACTIVE":
            print(f"  ✗ Unexpected state: {video_file.state.name}")
            return None

        print(f"  ✓ Video processed and ready")

        # Generate comprehensive analysis
        prompt = f"""Analyze this video from the Luoxi medical incident comprehensively.

Video: {video_name}

Provide detailed analysis covering:

## 1. Content Summary
- What happens in this video (chronological description)
- Estimated duration and key segments
- People shown (identify roles: mother, father, grandmother, officials, police, supporters)
- Locations (hospital, home, government building, street protest, etc.)

## 2. Audio Transcription (Chinese → Text)
**CRITICAL: Transcribe ALL spoken Chinese audio with precise timestamps**
- Format: [MM:SS] Speaker: "Chinese text here"
- Identify speakers when possible (母亲/父亲/奶奶/官员/警察)
- Note emotional tone (crying, angry, pleading, defiant)
- Mark any background audio (crowd chants, music, etc.)

## 3. Visual Content Analysis
- Key scenes frame-by-frame
- Visible documents or evidence (medical records, autopsy reports, official letters)
- Protest signs and their text
- Social media screenshots visible on screen
- Hospital/government buildings
- Family grief moments
- Before/after photos of Luoxi
- Symbolic imagery (empty baby clothes, toys, feeding rituals)

## 4. Visible Text (OCR)
**Transcribe ALL visible Chinese text:**
- Protest signs
- Social media posts on screen
- Documents shown
- Subtitles or captions
- Building signs
- News headlines

## 5. Emotional Beats (Timestamped)
For each significant moment, provide:
- **Timestamp:** [MM:SS]
- **What's happening:** Brief description
- **Emotional impact:** grief/anger/tenderness/injustice/protest/solidarity
- **Visual elements:** What makes it powerful
- **Audio elements:** What's being said or heard
- **Why it matters:** Connection to the larger story

## 6. Viral Clip Identification
Identify 3-5 clips with HIGHEST viral potential:

### Clip 1: [Title]
- **Timestamp:** [MM:SS] to [MM:SS]
- **Duration:** X seconds
- **Why it works:**
  - Emotional hook (specific)
  - Universal appeal (why non-Chinese audiences care)
  - Visual impact (what you see)
- **Platform fit:**
  - TikTok: [Yes/No - why?]
  - Instagram Reels: [Yes/No - why?]
  - YouTube Shorts: [Yes/No - why?]
  - X/Twitter: [Yes/No - why?]
- **Viral score:** X/10 (justify)
- **Production notes:** How to edit/enhance this clip

[Repeat for clips 2-5]

## 7. Evidence & Documentation
- Medical documents visible: [Describe what's shown]
- Hospital interactions: [What officials say/do]
- Police confrontations: [How authorities respond]
- Public support: [Signs of solidarity]
- Media coverage: [Any news clips or screenshots]

## 8. Key Quotes (Most Powerful)
List 3-5 most powerful quotes from audio:
- **Quote (Chinese):** "原文"
- **Speaker:** [Who said it]
- **Context:** [When/why in the video]
- **Emotional weight:** [Why this matters]
- **Translation priority:** High/Medium/Low

## 9. Production Recommendations
- **Priority clips:** Which segments to use first
- **Platform strategy:** Where each clip works best
- **Editing approach:** Suggested cuts, subtitles, pacing
- **Narrative arc:** How this video fits in larger campaign
- **Content warnings:** Sensitive content to handle carefully

## 10. Translation Needs
List all Chinese content requiring translation, prioritized:
- **HIGH:** Critical quotes, protest signs, key documents
- **MEDIUM:** Social media posts, longer speeches
- **LOW:** Background text, less critical audio

---

**Be EXTREMELY specific with timestamps (MM:SS format).**
**Transcribe ALL Chinese audio and visible text.**
**Identify ACTIONABLE viral content opportunities.**
**Think like a viral content strategist - what makes people SHARE?**"""

        print(f"  → Generating comprehensive analysis...")

        try:
            response = self.model.generate_content(
                [video_file, prompt],
                generation_config=genai.GenerationConfig(
                    temperature=0.4,  # More focused analysis
                    max_output_tokens=8192  # Long detailed response
                )
            )

            analysis_text = response.text
            print(f"  ✓ Analysis complete ({len(analysis_text)} characters)")

        except Exception as e:
            print(f"  ✗ Analysis failed: {e}")
            genai.delete_file(video_file.name)
            return None

        # Save analysis
        analysis_data = {
            'video_name': video_name,
            'video_path': str(video_path),
            'file_size_mb': round(Path(video_path).stat().st_size / (1024*1024), 2),
            'analysis': analysis_text,
            'analyzed_at': datetime.now().isoformat(),
            'model': 'gemini-2.5-flash'
        }

        # Save JSON
        json_file = REPORTS_DIR / f"{video_name}_analysis.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(analysis_data, f, ensure_ascii=False, indent=2)

        # Save Markdown
        md_file = REPORTS_DIR / f"{video_name}_analysis.md"
        with open(md_file, 'w', encoding='utf-8') as f:
            f.write(f"# Video Analysis: {video_name}\n\n")
            f.write(f"**Video:** {Path(video_path).name}\n")
            f.write(f"**Size:** {analysis_data['file_size_mb']} MB\n")
            f.write(f"**Analyzed:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"**Model:** Gemini 2.5 Flash\n\n")
            f.write("---\n\n")
            f.write(analysis_text)

        print(f"  ✓ Saved: {md_file.name}")

        # Clean up uploaded file
        try:
            genai.delete_file(video_file.name)
            print(f"  ✓ Cleaned up uploaded file")
        except:
            pass

        return analysis_data

    def generate_master_report(self):
        """Generate comprehensive master report"""
        print(f"\n{'='*60}")
        print("Generating Master Report")
        print(f"{'='*60}\n")

        successful = [r for r in self.results if r is not None]
        failed = [r for r in self.results if r is None]

        # Master report data
        master_report = {
            'generated_at': datetime.now().isoformat(),
            'total_videos': len(self.results),
            'successful': len(successful),
            'failed': len(failed),
            'estimated_cost_usd': round(len(successful) * 0.02, 2),  # ~$0.02 per video
            'model': 'gemini-2.5-flash',
            'results': successful
        }

        # Save JSON
        master_file = REPORTS_DIR / "VIDEO-ANALYSIS-MASTER-REPORT.json"
        with open(master_file, 'w', encoding='utf-8') as f:
            json.dump(master_report, f, ensure_ascii=False, indent=2)

        # Generate markdown summary
        md_file = REPORTS_DIR / "VIDEO-ANALYSIS-MASTER-REPORT.md"
        with open(md_file, 'w', encoding='utf-8') as f:
            f.write("# Video Analysis Master Report\n\n")
            f.write(f"**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"**Model:** Gemini 2.5 Flash\n\n")
            f.write("---\n\n")
            f.write("## Summary\n\n")
            f.write(f"- **Total videos:** {len(self.results)}\n")
            f.write(f"- **Successfully analyzed:** {len(successful)}\n")
            f.write(f"- **Failed:** {len(failed)}\n")
            f.write(f"- **Estimated cost:** ~${master_report['estimated_cost_usd']}\n\n")
            f.write("---\n\n")
            f.write("## Successfully Analyzed Videos\n\n")

            if successful:
                for result in successful:
                    f.write(f"### {result['video_name']}\n\n")
                    f.write(f"- **File:** {Path(result['video_path']).name}\n")
                    f.write(f"- **Size:** {result['file_size_mb']} MB\n")
                    f.write(f"- **Analysis:** [`{result['video_name']}_analysis.md`](./{result['video_name']}_analysis.md)\n")
                    f.write(f"- **Analyzed:** {result['analyzed_at']}\n\n")

            if failed:
                f.write("---\n\n")
                f.write("## Failed Analyses\n\n")
                f.write(f"{len(failed)} videos failed to analyze\n\n")

            f.write("---\n\n")
            f.write("## Output Files\n\n")
            f.write("- Individual analyses: `reports/*_analysis.md`\n")
            f.write("- JSON data: `reports/*_analysis.json`\n")
            f.write("- This report: `reports/VIDEO-ANALYSIS-MASTER-REPORT.md`\n\n")
            f.write("---\n\n")
            f.write("## Next Steps\n\n")
            f.write("1. Review individual video analyses\n")
            f.write("2. Identify top viral clips across all videos\n")
            f.write("3. Extract Chinese transcriptions needing translation\n")
            f.write("4. Feed analyses to M2.0 Media Index Brief Creator\n")

        print(f"✓ Master report: {master_file}")
        print(f"✓ Summary: {md_file}")

        return master_report

    def run(self):
        """Run full analysis pipeline"""
        print(f"\n{'='*60}")
        print("Gemini 2.5 Flash Video Analysis Pipeline")
        print(f"{'='*60}\n")

        start_time = datetime.now()

        # Find videos
        video_extensions = ['.mp4', '.mov', '.avi', '.mkv', '.MP4', '.MOV']
        videos = []
        for ext in video_extensions:
            videos.extend(glob.glob(str(VIDEO_DIR / f"*{ext}")))

        if not videos:
            print("✗ No videos found in media/ directory")
            print(f"  Searched: {VIDEO_DIR}")
            return

        print(f"Found {len(videos)} videos:")
        for video in videos:
            size_mb = Path(video).stat().st_size / (1024*1024)
            print(f"  - {Path(video).name} ({size_mb:.1f} MB)")

        # Create output directory
        REPORTS_DIR.mkdir(parents=True, exist_ok=True)

        # Process each video
        print(f"\n{'='*60}")
        print(f"Analyzing {len(videos)} videos...")
        print(f"{'='*60}")

        for i, video_path in enumerate(videos, 1):
            print(f"\n[{i}/{len(videos)}] {Path(video_path).name}")
            print(f"{'='*60}")

            result = self.analyze_video(video_path)
            self.results.append(result)

            # Rate limiting (be respectful to Google API)
            if i < len(videos):
                print(f"  Waiting 3 seconds before next video...")
                time.sleep(3)

        # Generate master report
        master_report = self.generate_master_report()

        # Final summary
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()

        print(f"\n{'='*60}")
        print("Analysis Complete!")
        print(f"{'='*60}")
        print(f"Videos analyzed: {master_report['successful']}/{len(videos)}")
        print(f"Total time: {duration/60:.1f} minutes")
        print(f"Estimated cost: ~${master_report['estimated_cost_usd']}")
        print(f"Output: {REPORTS_DIR}")
        print(f"{'='*60}\n")

def main():
    """Entry point"""
    # Check API key
    if not os.getenv("GOOGLE_API_KEY"):
        print("\n✗ GOOGLE_API_KEY environment variable not set")
        print("\nPlease set your API key:")
        print("  export GOOGLE_API_KEY='your-key-here'")
        print("\nGet API key: https://aistudio.google.com/apikey")
        return

    analyzer = GeminiVideoAnalyzer()
    analyzer.run()

if __name__ == "__main__":
    main()
