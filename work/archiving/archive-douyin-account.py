#!/usr/bin/env python3
"""
Douyin Account Archiving Script
Automated archiving of @小洛熙妈妈 Douyin account
Generated by CEO Agent - Phase 1.5
"""

import asyncio
import aiohttp
import json
import os
from datetime import datetime
from pathlib import Path

# Configuration
TARGET_ACCOUNT = "小洛熙妈妈"  # @小洛熙妈妈
API_BASE_URL = "http://localhost:8000"
OUTPUT_DIR = Path("douyin-backup-" + datetime.now().strftime("%Y%m%d"))
MAX_VIDEOS = 1000  # Download up to 1000 videos (should cover entire account)

class DouyinArchiver:
    def __init__(self):
        self.session = None
        self.videos_downloaded = []
        self.errors = []

    async def init_session(self):
        """Initialize aiohttp session"""
        timeout = aiohttp.ClientTimeout(total=600)  # 10 min timeout per request
        self.session = aiohttp.ClientSession(timeout=timeout)

    async def close_session(self):
        """Close aiohttp session"""
        if self.session:
            await self.session.close()

    async def get_user_profile(self, username):
        """Get user profile and video list"""
        print(f"\n[1/4] Fetching profile for @{username}...")

        # Try different URL formats
        urls_to_try = [
            f"https://www.douyin.com/@{username}",
            f"https://www.douyin.com/user/{username}",
        ]

        for url in urls_to_try:
            try:
                async with self.session.post(
                    f"{API_BASE_URL}/api/hybrid/v1/parse",
                    json={"url": url}
                ) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        if data.get("status") == "success":
                            print(f"✓ Profile found: {url}")
                            return data
            except Exception as e:
                print(f"  ⚠ Failed to fetch {url}: {e}")
                continue

        raise Exception(f"Could not fetch profile for @{username}")

    async def search_user_videos(self, username):
        """Search for all videos from user"""
        print(f"\n[2/4] Searching for videos from @{username}...")

        # Use search API to find user's videos
        search_url = f"https://www.douyin.com/search/{username}"

        try:
            async with self.session.post(
                f"{API_BASE_URL}/api/hybrid/v1/parse",
                json={"url": search_url}
            ) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    print(f"✓ Search results retrieved")
                    return data
        except Exception as e:
            print(f"⚠ Search failed: {e}")
            return None

    async def download_video(self, video_url, video_id, title):
        """Download a single video"""
        try:
            # Parse video URL via API
            async with self.session.post(
                f"{API_BASE_URL}/api/hybrid/v1/parse",
                json={"url": video_url}
            ) as resp:
                if resp.status != 200:
                    raise Exception(f"API returned status {resp.status}")

                data = await resp.json()

                if data.get("status") != "success":
                    raise Exception(f"Parse failed: {data.get('message')}")

                video_data = data.get("data", {})
                download_url = video_data.get("video_url") or video_data.get("download_url")

                if not download_url:
                    raise Exception("No download URL in response")

            # Download video file
            async with self.session.get(download_url) as resp:
                if resp.status != 200:
                    raise Exception(f"Download failed with status {resp.status}")

                # Save video
                filename = f"{video_id}_{self._sanitize_filename(title)}.mp4"
                filepath = OUTPUT_DIR / "videos" / filename

                with open(filepath, 'wb') as f:
                    while True:
                        chunk = await resp.read(8192)
                        if not chunk:
                            break
                        f.write(chunk)

            # Save metadata
            metadata = {
                "video_id": video_id,
                "title": title,
                "url": video_url,
                "download_url": download_url,
                "downloaded_at": datetime.now().isoformat(),
                "file_size": os.path.getsize(filepath),
                "filename": filename,
                **video_data
            }

            self.videos_downloaded.append(metadata)

            return True, filepath

        except Exception as e:
            error = {
                "video_id": video_id,
                "video_url": video_url,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
            self.errors.append(error)
            return False, str(e)

    def _sanitize_filename(self, filename):
        """Remove invalid characters from filename"""
        invalid_chars = '<>:"/\\|?*'
        for char in invalid_chars:
            filename = filename.replace(char, '_')
        return filename[:100]  # Limit length

    async def archive_account(self, username):
        """Main archiving workflow"""
        print(f"\n{'='*60}")
        print(f"Douyin Account Archiving: @{username}")
        print(f"{'='*60}")

        await self.init_session()

        try:
            # Note: The Douyin_TikTok_Download_API doesn't provide a direct
            # "get all user videos" endpoint. We need to either:
            # 1. Manually collect video URLs from the user's profile
            # 2. Use search to find videos
            # 3. Have a list of video URLs to download

            # For now, this script provides the framework.
            # You'll need to populate video_urls list with actual URLs from @小洛熙妈妈

            print("\n[3/4] Loading video URLs...")
            print("⚠ This script requires a list of video URLs to download.")
            print("⚠ Please manually collect URLs from @小洛熙妈妈 Douyin profile")
            print("⚠ Or use the web interface at http://localhost:8000")
            print("")
            print("For batch downloading:")
            print("1. Go to http://localhost:8000")
            print("2. Paste video URLs (one per line)")
            print("3. Videos will be downloaded to the server")
            print("")

            # Example: If you have video URLs
            video_urls = [
                # "https://www.douyin.com/video/1234567890",
                # "https://www.douyin.com/video/0987654321",
                # Add video URLs here
            ]

            if not video_urls:
                print("⚠ No video URLs provided. Exiting.")
                print("")
                print("ALTERNATIVE APPROACH:")
                print("Use the web UI at http://localhost:8000 for batch downloads")
                return

            print(f"✓ {len(video_urls)} videos to download")

            # Download all videos
            print(f"\n[4/4] Downloading videos...")
            for i, url in enumerate(video_urls, 1):
                print(f"\n[{i}/{len(video_urls)}] Downloading: {url}")

                # Extract video ID from URL
                video_id = url.split('/')[-1].split('?')[0]

                success, result = await self.download_video(url, video_id, f"video_{video_id}")

                if success:
                    print(f"  ✓ Downloaded: {result}")
                else:
                    print(f"  ✗ Failed: {result}")

                # Rate limiting
                await asyncio.sleep(2)

            # Save summary
            await self.save_summary()

        finally:
            await self.close_session()

    async def save_summary(self):
        """Save archiving summary"""
        summary = {
            "account": TARGET_ACCOUNT,
            "archived_at": datetime.now().isoformat(),
            "total_videos": len(self.videos_downloaded),
            "total_errors": len(self.errors),
            "videos": self.videos_downloaded,
            "errors": self.errors
        }

        # Save JSON
        summary_file = OUTPUT_DIR / "metadata" / "archive-summary.json"
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)

        # Save CSV
        csv_file = OUTPUT_DIR / "metadata" / "archive-summary.csv"
        with open(csv_file, 'w', encoding='utf-8') as f:
            f.write("video_id,title,url,filename,file_size,downloaded_at\n")
            for video in self.videos_downloaded:
                f.write(f"{video['video_id']},{video['title']},{video['url']},{video['filename']},{video['file_size']},{video['downloaded_at']}\n")

        print(f"\n{'='*60}")
        print(f"Archiving Complete!")
        print(f"{'='*60}")
        print(f"Videos downloaded: {len(self.videos_downloaded)}")
        print(f"Errors: {len(self.errors)}")
        print(f"Output directory: {OUTPUT_DIR}")
        print(f"Metadata: {summary_file}")
        print(f"{'='*60}\n")

async def main():
    """Entry point"""
    # Check if Docker container is running
    print("Checking if Douyin API is running...")
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(f"{API_BASE_URL}/", timeout=aiohttp.ClientTimeout(total=5)) as resp:
                if resp.status == 200:
                    print("✓ Douyin API is running\n")
                else:
                    print(f"⚠ API returned status {resp.status}")
    except Exception as e:
        print(f"✗ Could not connect to API: {e}")
        print("\nPlease ensure Docker container is running:")
        print("  cd work/archiving")
        print("  docker-compose up -d")
        return

    # Run archiver
    archiver = DouyinArchiver()
    await archiver.archive_account(TARGET_ACCOUNT)

if __name__ == "__main__":
    asyncio.run(main())
